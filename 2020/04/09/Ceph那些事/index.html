<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/abitming.github.io/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/abitming.github.io/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/abitming.github.io/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/abitming.github.io/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/abitming.github.io/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/abitming.github.io/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/abitming.github.io/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Ceph，存储,">










<meta name="description" content="Ceph集群部署及线上故障处理">
<meta name="keywords" content="Ceph，存储">
<meta property="og:type" content="article">
<meta property="og:title" content="Ceph初探">
<meta property="og:url" content="https://abitming.github.io/2020/04/09/Ceph那些事/index.html">
<meta property="og:site_name" content="冒了个小小泡">
<meta property="og:description" content="Ceph集群部署及线上故障处理">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2020-04-21T12:01:04.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Ceph初探">
<meta name="twitter:description" content="Ceph集群部署及线上故障处理">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/abitming.github.io/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://abitming.github.io/2020/04/09/Ceph那些事/">





  <title>Ceph初探 | 冒了个小小泡</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/abitming.github.io/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">冒了个小小泡</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">小明的博客</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/abitming.github.io/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/abitming.github.io/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://abitming.github.io/abitming.github.io/2020/04/09/Ceph那些事/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="小明">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/abitming.github.io/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="冒了个小小泡">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Ceph初探</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-04-09T16:05:01+08:00">
                2020-04-09
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          
              <div class="post-description">
                  Ceph集群部署及线上故障处理
              </div>
          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="Ceph部署"><a href="#Ceph部署" class="headerlink" title="Ceph部署"></a>Ceph部署</h1><h3 id="一、环境准备-ceph-deploy"><a href="#一、环境准备-ceph-deploy" class="headerlink" title="一、环境准备(ceph-deploy)"></a>一、环境准备(ceph-deploy)</h3><h4 id="node-节点的YUM环境准备"><a href="#node-节点的YUM环境准备" class="headerlink" title="node 节点的YUM环境准备"></a>node 节点的YUM环境准备</h4><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#更新YUM源(更新/etc/yum.repos.d/ 和 /etc/pki/rpm-gpg/ 目录文件)。文件在Github仓库中</span></span><br></pre></td></tr></table></figure>
<h3 id="二、安装部署"><a href="#二、安装部署" class="headerlink" title="二、安装部署"></a>二、安装部署</h3><h4 id="1、创建集群"><a href="#1、创建集群" class="headerlink" title="1、创建集群"></a>1、创建集群</h4><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph-depoly new node1</span><br></pre></td></tr></table></figure>
<p> 如果在机器之前部署了ceph，依次执行：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ceph-deploy purge node1 node2 node3</span><br><span class="line">ceph-deploy purgedata node1 node2 node3</span><br><span class="line">ceph-deploy forgetkeys</span><br></pre></td></tr></table></figure>
<h4 id="2、修改副本"><a href="#2、修改副本" class="headerlink" title="2、修改副本"></a>2、修改副本</h4><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#把 Ceph 配置文件里的默认副本数从 3 改成 2 ，这样只有两个 OSD 也可以达到 active + clean 状态。把下面这行加入 [global] 段</span></span><br><span class="line">osd pool default size = <span class="number">2</span></span><br></pre></td></tr></table></figure>
<h4 id="3、网络设置"><a href="#3、网络设置" class="headerlink" title="3、网络设置"></a>3、网络设置</h4><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#如果你有多个网卡，可以把 public network 写入 Ceph 配置文件的 [global] 段下</span></span><br><span class="line">public network = <span class="number">10.79</span>.<span class="number">112.0</span>/<span class="number">24</span></span><br></pre></td></tr></table></figure>
<h4 id="4、安装ceph"><a href="#4、安装ceph" class="headerlink" title="4、安装ceph"></a>4、安装ceph</h4><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph-deploy install node1 node2 node3</span><br></pre></td></tr></table></figure>
<p>也可以手动去每台机器上手动执行安装命令：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install ceph ceph-radosgw</span><br></pre></td></tr></table></figure>
<h4 id="5、初始化MON"><a href="#5、初始化MON" class="headerlink" title="5、初始化MON"></a>5、初始化MON</h4><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph-deploy mon create-initial</span><br></pre></td></tr></table></figure>
<p>操作完成之后会出现以下密钥环：</p>
<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;cluster-name&#125;.client.admin.keyring</span><br><span class="line">&#123;cluster-name&#125;.bootstrap-osd.keyring </span><br><span class="line">&#123;cluster-name&#125;.bootstrap-mds.keyring </span><br><span class="line">&#123;cluster-name&#125;.bootstrap-rgw.keyring</span><br></pre></td></tr></table></figure>
<h4 id="6、添加OSD"><a href="#6、添加OSD" class="headerlink" title="6、添加OSD"></a>6、添加OSD</h4><h5 id="6-1、在-OSD-节点上的准备工作"><a href="#6-1、在-OSD-节点上的准备工作" class="headerlink" title="6.1、在 OSD 节点上的准备工作"></a>6.1、在 OSD 节点上的准备工作</h5><p>​         创建用户为 ceph:ceph  权限为 755 的存储目录 /data1/data_ceph</p>
<h5 id="6-2、在管理节点准备-OSD"><a href="#6-2、在管理节点准备-OSD" class="headerlink" title="6.2、在管理节点准备 OSD"></a>6.2、在管理节点准备 OSD</h5><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph-deploy osd prepare node2:/<span class="keyword">data</span>1/data_ceph node3:/<span class="keyword">data</span>1/data_ceph</span><br></pre></td></tr></table></figure>
<h5 id="6-3、在管理节点上激活-OSD"><a href="#6-3、在管理节点上激活-OSD" class="headerlink" title="6.3、在管理节点上激活 OSD"></a>6.3、在管理节点上激活 OSD</h5><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph-deploy osd activate node2:/<span class="keyword">data</span>1/data_ceph node3:/<span class="keyword">data</span>1/data_ceph</span><br></pre></td></tr></table></figure>
<h4 id="7、密钥复制"><a href="#7、密钥复制" class="headerlink" title="7、密钥复制"></a>7、密钥复制</h4><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#用 ceph-deploy 把配置文件和 admin 密钥拷贝到管理节点和 Ceph 节点，这样你每次执行 Ceph 命令行时就无需指定 monitor 地址和 ceph.client.admin.keyring 了</span></span><br><span class="line">ceph-deploy  --overwrite-conf admin node1 node2 node3</span><br></pre></td></tr></table></figure>
<p>当然最好的方式是把 ceph-deploy 执行的目录下的文件，全部copy 到 集群各个节点的/etc/ceph 下。</p>
<h4 id="8、检查集群状态"><a href="#8、检查集群状态" class="headerlink" title="8、检查集群状态"></a>8、检查集群状态</h4> <figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph -s</span><br></pre></td></tr></table></figure>
<h3 id="三、集群扩容"><a href="#三、集群扩容" class="headerlink" title="三、集群扩容"></a>三、集群扩容</h3><h4 id="1、MON-新增"><a href="#1、MON-新增" class="headerlink" title="1、MON 新增"></a>1、MON 新增</h4><table><tr><td bgcolor="orange">Ceph 集群规定，mon 的数量(法定人数 - quorum )应为 奇数个(至少为 1 个)，但是为了保证生产环境的高可用，线上应该至少保持 3 个 mon  节点</td></tr></table>

<h5 id="1-1-修改-ceph-conf-配置文件"><a href="#1-1-修改-ceph-conf-配置文件" class="headerlink" title="1.1 修改 ceph.conf 配置文件"></a>1.1 修改 ceph.conf 配置文件</h5><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 增加 mon_initial_members 和 mon_host,下发配置文件到所有节点</span></span><br><span class="line">ceph-deploy  --overwrite-conf admin node1 node2 node3</span><br></pre></td></tr></table></figure>
<h5 id="1-2-新增-MON"><a href="#1-2-新增-MON" class="headerlink" title="1.2 新增 MON"></a>1.2 新增 MON</h5><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ceph-deploy mon create node2</span><br><span class="line"><span class="comment"># 登陆 MON 节点,ceph -s 查看 mon 是否添加成功。如果未成功查看一下机器上的mon进程是否启动。</span></span><br></pre></td></tr></table></figure>
<h4 id="2、OSD-新增"><a href="#2、OSD-新增" class="headerlink" title="2、OSD 新增"></a>2、OSD 新增</h4><h5 id="2-1-修改ceph-conf"><a href="#2-1-修改ceph-conf" class="headerlink" title="2.1 修改ceph.conf"></a>2.1 修改ceph.conf</h5><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#可适当修改 ceph.conf 中 osd pool default size = 2 的值(这个根据集群节点的数目而定)。下发配置文件到所有节点</span></span><br><span class="line">ceph-deploy  --overwrite-conf admin node1 node2 node3</span><br></pre></td></tr></table></figure>
<h5 id="2-2-目录授权"><a href="#2-2-目录授权" class="headerlink" title="2.2 目录授权"></a>2.2 目录授权</h5><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">chown -R ceph:ceph /<span class="keyword">data</span>1/data_ceph </span><br><span class="line">chmod <span class="number">755</span> /<span class="keyword">data</span>1/data_ceph</span><br></pre></td></tr></table></figure>
<h5 id="2-3-准备并激活"><a href="#2-3-准备并激活" class="headerlink" title="2.3 准备并激活"></a>2.3 准备并激活</h5><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在管理节点准备并激活 OSD</span></span><br><span class="line">ceph-deploy osd prepare node3:/<span class="keyword">data</span>1/data_ceph</span><br><span class="line">eph-deploy osd activate node3:/<span class="keyword">data</span>1/data_ceph</span><br><span class="line"><span class="comment"># 在MON上查看OSD状态</span></span><br><span class="line">ceph osd tree</span><br><span class="line">ceph -s</span><br></pre></td></tr></table></figure>
<h4 id="3、MDS-新增"><a href="#3、MDS-新增" class="headerlink" title="3、MDS 新增"></a>3、MDS 新增</h4><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 管理节点上执行</span></span><br><span class="line">ceph-deploy mds create node3</span><br><span class="line"><span class="comment"># 在 MON 上查看是否成功</span></span><br><span class="line">ceph mds stat</span><br></pre></td></tr></table></figure>
<h2 id="四、集群管理"><a href="#四、集群管理" class="headerlink" title="四、集群管理"></a>四、集群管理</h2><h4 id="1、创建Pool"><a href="#1、创建Pool" class="headerlink" title="1、创建Pool"></a>1、创建Pool</h4><table><tr><td bgcolor="orange">Pool 中 PG 数量的计算方法 :<br><br>  Total PGs = ((Total_number_of_OSD * 100) / max_replication_count) / pool_count<br><br>  在集群建设之初需要考虑好后期集群的规模，最好不要后期调整 pool 的 PG 数</td></tr></table>

<figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建 pool</span></span><br><span class="line">ceph osd pool create cephfs_data</span><br><span class="line"><span class="comment"># 删除 pool</span></span><br><span class="line">ceph osd pool delete &#123;pool_name&#125; &#123;pool_name&#125; --yes-i-really-really-mean-it</span><br><span class="line"><span class="comment"># 查看 pool 对应的 crush_rule</span></span><br><span class="line">ceph osd pool get &#123;pool_name&#125; crush_ruleset</span><br></pre></td></tr></table></figure>
<h4 id="2、创建-CephFS"><a href="#2、创建-CephFS" class="headerlink" title="2、创建 CephFS"></a>2、创建 CephFS</h4><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建两个存储池</span></span><br><span class="line">ceph osd pool create cephfs_data</span><br><span class="line">ceph osd pool create cephfs_metadata</span><br><span class="line"><span class="comment"># 创建文件系统</span></span><br><span class="line">ceph fs new</span><br><span class="line"><span class="comment"># 查看文件系统</span></span><br><span class="line">ceph fs ls</span><br></pre></td></tr></table></figure>
<h4 id="3、CephFS用户授权"><a href="#3、CephFS用户授权" class="headerlink" title="3、CephFS用户授权"></a>3、CephFS用户授权</h4><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建用户</span></span><br><span class="line">ceph auth add client.&#123;name&#125;  eg.  ceph auth add client.nami</span><br><span class="line"><span class="comment"># 用户授权</span></span><br><span class="line">ceph auth caps  client.sanji mon <span class="string">'allow *'</span> osd <span class="string">'allow *'</span> mds <span class="string">'allow *</span></span><br></pre></td></tr></table></figure>
<h4 id="4、创建RBD"><a href="#4、创建RBD" class="headerlink" title="4、创建RBD"></a>4、创建RBD</h4><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个 pool，如 Docker_Pool </span></span><br><span class="line">ceph osd pool create Docker_Pool <span class="number">100</span></span><br><span class="line"><span class="comment"># 创建一个指定大小的镜像(image)。如 10G 大小的名为 Docker 的 image </span></span><br><span class="line">rbd create Docker_Pool/Docker --size <span class="number">10240</span></span><br><span class="line"><span class="comment"># Map Image</span></span><br><span class="line">rbd map Docker -p Docker_Pool</span><br><span class="line"><span class="comment"># 挂载</span></span><br><span class="line">mount /dev/rbd0 /opt/test</span><br></pre></td></tr></table></figure>
<h4 id="5、数据控制"><a href="#5、数据控制" class="headerlink" title="5、数据控制"></a>5、数据控制</h4><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看 指定 map 的数据及数据副本分布</span></span><br><span class="line">crushtool -i &#123;mapname&#125; --test --min-x <span class="number">0</span> --max-x <span class="number">9</span> --num-rep <span class="number">3</span> --ruleset <span class="number">0</span> --show_mappings</span><br></pre></td></tr></table></figure>
<h2 id="五、故障处理"><a href="#五、故障处理" class="headerlink" title="五、故障处理"></a>五、故障处理</h2><ul>
<li><font color="red">集群报错：  health HEALTH_ERR . 1 pgs inconsistent.   4 scrub error</font>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">(1)、ceph health detail 找到出问题的 pg</span><br><span class="line">(2)、ceph pg repair &lt;pg_id&gt;</span><br><span class="line">(3)、如果无法修复，ceph health detail 可以看到出问题的 osd</span><br><span class="line">     查看 osd 的日志 </span><br><span class="line">     错误类型：</span><br><span class="line">         repair 3.fe 3:7f3c576e:::1002b16fb14.00000013:head on disk size (0) 	</span><br><span class="line">         does not match object info size (2097152) adjusted for ondisk to (2097152)</span><br><span class="line">     原因：</span><br><span class="line">         1002b16fb14.00000013 这个object的大小为空，没法自动调整到 2097152 大小</span><br><span class="line">     处理：</span><br><span class="line">         执行 rados -p &lt;pool_name&gt; truncate 1002b16fb14.00000013 2097152，</span><br><span class="line">         然后再执行 ceph pg repair &lt;pg_id&gt; 就OK了</span><br></pre></td></tr></table></figure>
</li>
<li><font color="red">增加MON节点报错</font>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">报错信息：</span><br><span class="line">    Running command: ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.ceph192.asok mon_status</span><br><span class="line">    admin_socket: exception getting command descriptions: [Errno 2] No such file or directory</span><br><span class="line">    </span><br><span class="line">解决：</span><br><span class="line">   需要现在节点上启动 MON 进程，登陆到对应节点用 systemctl 启动</span><br></pre></td></tr></table></figure>
</li>
<li><font color="red">MON节点启动失败</font>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">报错信息：</span><br><span class="line">	no public_addr or public_network specified, and mon.ceph192 not present in monmap or ceph.conf</span><br><span class="line"></span><br><span class="line">解决：</span><br><span class="line">	这个是由于配置文件中没有添加对外ceph集群对外公开的访问地址，是一个区间值</span><br><span class="line">  在配置文件中添加</span><br><span class="line">  public_network = 10.77.16.0/24（网段肯定具体使用的网段确定）</span><br></pre></td></tr></table></figure>
</li>
<li><font color="red">RBD挂载失败</font>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">报错信息：</span><br><span class="line">	mount: /dev/rbd0 is write-protected, mounting read-only</span><br><span class="line">		</span><br><span class="line">解决：</span><br><span class="line">	根据文件系统清空 map</span><br><span class="line">	mkfs.ext4 /dev/rbd0</span><br></pre></td></tr></table></figure>
</li>
<li><font color="red">RBD map 失败</font>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">报错信息：</span><br><span class="line">	rbd: sysfs write failed</span><br><span class="line">	RBD image feature set mismatch. You can disable features unsupported by the kernel with &quot;rbd feature disable&quot;.</span><br><span class="line">	In some cases useful info is found in syslog - try &quot;dmesg | tail&quot; or so.</span><br><span class="line">	rbd: map failed: (6) No such device or address</span><br><span class="line">		</span><br><span class="line">解决：</span><br><span class="line">	features 多种类型文件系统不支持导致</span><br><span class="line">	rbd info docker/code 查看features 类型</span><br><span class="line">	rbd feature disable docker/code exclusive-lock, object-map, fast-diff, deep-flatten</span><br><span class="line">	只保留 layering 分层</span><br></pre></td></tr></table></figure>
</li>
<li><font color="red">安装报错</font>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">报错信息：</span><br><span class="line">	GPG key retrieval failed: [Errno 14]......</span><br><span class="line"></span><br><span class="line">解决：</span><br><span class="line">	修改 ceph.rpeo文件参数</span><br><span class="line">	gpgcheck=0</span><br></pre></td></tr></table></figure>
</li>
<li><font color="red">CephFS连续写大文件速度越来越慢问题</font>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">现象：</span><br><span class="line">	客户端写大文件速度逐渐变得很慢，甚至变到了 50几MB/s</span><br><span class="line">		</span><br><span class="line">解决：</span><br><span class="line">	(1)增加 ceph 集群 client IO 监控，查看是否有异常</span><br><span class="line"> 	(2)增加 OSD 磁盘监控 osd commit latency 和 osd apply latency 监控，查看是否有异常</span><br><span class="line"> 	(3)增加 客户端网络监控，看看是不是客户端网卡跑慢了(一般都是这个原因)</span><br></pre></td></tr></table></figure>
</li>
<li><font color="red">初始化集群报错</font>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">报错信息：</span><br><span class="line">	admin_socket: exception getting command descriptions: [Errno 2] No such file or directory</span><br><span class="line"></span><br><span class="line">解决：</span><br><span class="line">	存在节点 hostname 有问题；先踢出有问题 mon ，修改节点hostname ，删除有问题的hostname.service ,重新 init</span><br></pre></td></tr></table></figure>
</li>
<li><font color="red">节点时钟不同步</font>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">报错信息：</span><br><span class="line">	clock skew detected on mon.ceph-yf-75</span><br><span class="line">		</span><br><span class="line">解决：</span><br><span class="line">	节点时钟和其他节点时钟偏差较大导致，对有问题节点进行时钟同步；同步完成之后重启 mon</span><br></pre></td></tr></table></figure>
</li>
<li><font color="red">PG不一致</font>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">报错信息：</span><br><span class="line">	HEALTH_ERR 1 pgs inconsistent; 1 scrub errors</span><br><span class="line">	pg 5.5d is active+clean+inconsistent, acting [4,2,0]</span><br><span class="line">	1 scrub errors</span><br><span class="line">		</span><br><span class="line">解决：</span><br><span class="line">	1、查看有问题的 pg</span><br><span class="line">	 ceph health detail</span><br><span class="line">	2、修复pg</span><br><span class="line">	 ceph pg repair 5.5d</span><br><span class="line">	二、如果上种方式没有修复尝试此方式</span><br><span class="line">	 1、ceph pg scrub 5.5d   </span><br><span class="line">	 2、ceph pg deep-scrub 5.5d</span><br><span class="line">	 3、ceph pg repair 2.37c</span><br><span class="line">	三、如果以上两种方式都不能解决尝试此方式</span><br><span class="line">	 1、查看有问题的osd</span><br><span class="line">	  ceph pg  5.dd query |grep primary</span><br><span class="line">	 2、修复整个 OSD(osd.13 是有问题的)   </span><br><span class="line">	  ceph osd repair 13</span><br><span class="line">	四、如果以上三种方式都不能解决尝试此方式(很暴力)</span><br><span class="line">	 1、停止有问题的 osd</span><br><span class="line">	  systemctl stop ceph-osd@13.service</span><br><span class="line">	  这个时候数据会重新调整，但是你会发现这个速度简直慢的很。可以选择重新调整 osdmap ，直接把 osd.13 下了！！</span><br></pre></td></tr></table></figure>
</li>
<li><font color="red">MDS异常</font>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">报错信息：</span><br><span class="line">	HEALTH_WARN mds0: Client skuld60:luffy failing to respond to cache pressure; mds0: Client skuld59:luffy failing to respond to cache pressure</span><br><span class="line">		</span><br><span class="line">解决：</span><br><span class="line">	由于 mds 的 mds_cache_size 参数值设置过小导致</span><br><span class="line">	查看 mds 配置参数：ceph daemon mds.0 config show</span><br><span class="line">	动态更新参数： </span><br><span class="line">	  ceph daemon mds.0 config set mds_cache_size 500000</span><br><span class="line">	查看参数信息：</span><br><span class="line">	  ceph daemon mds.0 config get mds_cache_size</span><br><span class="line">	  动态加载是临时生效，重启之后恢复原状，希望永久修改请修改 ceph.conf 文件</span><br></pre></td></tr></table></figure>
</li>
<li><font color="red">集群异常</font>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">报错信息：</span><br><span class="line">	health HEALTH_ERR ; 64 pgs are stuck inactive for more than 300 seconds</span><br><span class="line">		</span><br><span class="line">解决：</span><br><span class="line">	1、osd pool default pg num = 256</span><br><span class="line">	  osd pool default pgp num = 256</span><br><span class="line">	  如果不行，直接删除这个 pool</span><br><span class="line">	  ceph osd pool delete rbd rbd --yes-i-really-really-mean-it</span><br><span class="line">	2、ceph -s 会发现 pgs 一直在 creating</span><br><span class="line">	  这个是因为新增 OSD 或者 OSD有变动  crushmap 没有更新。osd_crush_update_on_start 这个参数默认为 false。合理更新crushmap 就OK了~~</span><br></pre></td></tr></table></figure>
</li>
<li><font color="red">OSD down</font>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">情景：</span><br><span class="line">	ceph 集群部署时，新增osd 出现 osd down 状态 ：2 osds: 0 up, 0 in</span><br><span class="line">	</span><br><span class="line">解决：</span><br><span class="line">	同步管理机的keyring 到目标机器上的 /etc/ceph 目录下</span><br></pre></td></tr></table></figure>
</li>
<li><font color="red">OSD Weight 为 0</font>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">现象：</span><br><span class="line">	新增 osd 节点激活之后，ceph osd tree 发现 weight 是 0</span><br><span class="line">	</span><br><span class="line">解决：</span><br><span class="line">	1、ceph osd getcrushmap -o map_old    导出map</span><br><span class="line">	2、crushtool -d map_old -o map_old.txt  转化成可编辑格式</span><br><span class="line">	  查看新增的 OSD 是否在 crush map 中，如果不在执行以下步骤</span><br><span class="line">	3、crushtool -c map_new.txt -o map_new  还原为map</span><br><span class="line">	4、ceph osd setcrushmap -i map_new     将map导入ceph</span><br><span class="line">	  调整 crush map 也用作来调整 不同存储大小的 OSD</span><br></pre></td></tr></table></figure>
</li>
<li><font color="red">MDS异常</font>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">报错信息:</span><br><span class="line">	mds0: Client hathor225:zoro failing to advance its oldest client/flush tid</span><br><span class="line">原因:</span><br><span class="line">	CephFS 的客户端-MDS 协议有一个名为 oldest tid 的字段，可让客户端通知 MDS 哪些请求全部完成了，这样的话它就有可能被 MDS 遗忘。如果一个有缺陷的客户端未能上报这个字段，那么与之相关的 MDS 就不能擅自清理这些请求所占用的资源。如果某个客户端的请求在 MDS 端已完成、但尚未收到客户端上报的 oldest tid 值，这样的请求数量超过max_completed_requests （默认为 100000 ）时，此消息就会出现。</span><br><span class="line">	官网解释： http://docs.ceph.com/docs/master/cephfs/health-messages/</span><br><span class="line">	</span><br><span class="line">解决：</span><br><span class="line">	1、找到有问题的 session id</span><br><span class="line">	  ceph tell mds.0 session ls</span><br><span class="line">	2、将有问题的session 驱逐</span><br><span class="line">	  ceph tell mds.0 session evict id=14264</span><br></pre></td></tr></table></figure>
</li>
<li><font color="red">MDS异常</font>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">报错信息：</span><br><span class="line">	mds0: Client name failing to respond to cache pressure</span><br><span class="line">原因：</span><br><span class="line">	客户端有各自的元数据缓存，客户端缓存中的条目（比如索引节点）也会存在于 MDS 缓存中，所以当 MDS 需要削减其缓存时（保持在 mds_cache_size 以下），它也会发消息给客户端让它们削减自己的缓存。如果有客户端没响应或者有缺陷，就会妨碍 MDS 将缓存保持在 mds_cache_size 以下， MDS 就有可能耗尽内存而后崩溃。如果某个客户端的响应时间超过了 mds_recall_state_timeout （默认为 60s ），这条消息就会出现。</span><br><span class="line">解释：</span><br><span class="line">	1、挂载的客户端有问题，客户端没有及时的清理cache，这个和系统等都相关。但是一般这个可能性比较小</span><br><span class="line">	2、MDS有问题，MDS设置的inode最大值太小了</span><br><span class="line">  </span><br><span class="line">解决：</span><br><span class="line">	1、查看当前MDS inode使用情况</span><br><span class="line">	  ceph daemon mds.hathor124 perf dump mds</span><br><span class="line">	  如果 inode_max 小于 inode ，那么就说明服务端cache不足了，调整 mds cache size 大小。</span><br><span class="line">	2、调整 mds cache size 大小(默认值是 10000)，根据当前 inode的大小有规划的调整 mds cache size 值，我们这里调整为 3000000 。重启 MDS 。</span><br></pre></td></tr></table></figure>
</li>
<li><font color="red">MDS异常</font>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">报错信息：</span><br><span class="line">	mds0: Behind on trimming</span><br><span class="line">原因：</span><br><span class="line">	CephFS维护一个分为日志段的元数据日志。日志的长度（段数）由mds_log_max_segments设置控制。当段数超过该设置时，MDS开始写回元数据，以便它可以删除（修剪）最旧的段。如果此过程太慢，或软件错误阻止修剪，则会显示此健康消息。显示此消息的阈值是段的数量为双倍mds_log_max_segments。</span><br><span class="line">	官方文档：https://ceph.seekerliu.com/cephfs/health-messages/</span><br><span class="line"></span><br><span class="line">解决：</span><br><span class="line">	这个问题多半是由于 mds0: Client hathor225:zoro failing to advance its oldest client/flush tid 这个问题引起的，这个并不影响整个集群的功能，理论上可以忽略。一般在运行一段时间之后可能会再次出现 oldest client/flush。再次处理 oldest client/flush 报错报警就会恢复。</span><br></pre></td></tr></table></figure>
</li>
<li><font color="red">Pool异常</font>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">报错信息：</span><br><span class="line">	pool cephfs_data has many more objects per pg than average (too few pgs?)</span><br><span class="line">分析：</span><br><span class="line">	mon_pg_warn_min_objects = 10000 //总的对象超过10000</span><br><span class="line">	mon_pg_warn_min_pool_objects = 1000 //存储池对象超过1000</span><br><span class="line">	mon_pg_warn_max_object_skew = 10 //就是上面的存储池的平均对象与所有pg的平均值的倍数关系</span><br><span class="line">	1、cephfs_data 通过 ceph df 可以看到cephfs_pool 总 Objects的数量 A</span><br><span class="line">	2、ceph osd pool get cephfs_data pg_num 可以看到pg 的数量 B</span><br><span class="line">	3、ceph -s 可以看到每个pool的平均pg数量 C</span><br></pre></td></tr></table></figure>
</li>
<li><font color="red">MDS集群崩溃</font>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">报错信息:</span><br><span class="line">	mds cluster is degraded ，集群状态为 error</span><br><span class="line"></span><br><span class="line">原因:</span><br><span class="line">	ceph health detail 会看到报错的原因，如果是某的 osd 比较慢，重启osd即可，但是实际的情况可能比较复杂，会出现多了osd 比较慢的情况。</span><br><span class="line">		</span><br><span class="line">解决：</span><br><span class="line">	找到出现pg异常最多的那个osd 重启。</span><br></pre></td></tr></table></figure>
</li>
<li><font color="red">OSD进程挂掉，并没有自动重启</font>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">原因：</span><br><span class="line">	/usr/lib/systemd/system/ceph-osd@.service 未设置自动启动OSD服务</span><br><span class="line">解决：</span><br><span class="line">	修改以下配置参数：</span><br><span class="line">	Restart=always</span><br><span class="line">	StartLimitInterval=30min</span><br><span class="line">	StartLimitBurst=3</span><br><span class="line">	RestartSec=10s</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="六、配置文件参考"><a href="#六、配置文件参考" class="headerlink" title="六、配置文件参考"></a>六、配置文件参考</h2><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line">[global]</span><br><span class="line">fsid = e1a47a21-<span class="number">190</span>d-<span class="number">4534</span>-a1ad-f196d340ae2e</span><br><span class="line">mon_initial_members = hathor124, skuld98, kotl29</span><br><span class="line">mon_host = x.x.x.x,y.y.y.y,w.w.w.w</span><br><span class="line">auth_cluster_required = cephx</span><br><span class="line">auth_service_required = cephx</span><br><span class="line">auth_client_required = cephx</span><br><span class="line">public network = <span class="number">10.13</span>.<span class="number">12.0</span>/<span class="number">24</span>,<span class="number">10.72</span>.<span class="number">11.0</span>/<span class="number">24</span>,<span class="number">10.11</span>.<span class="number">29.0</span>/<span class="number">24</span></span><br><span class="line">;cluster network = <span class="number">1.1</span>.<span class="number">1.0</span>/<span class="number">24</span></span><br><span class="line">filestore xattr use omap = true</span><br><span class="line">mds max file size = <span class="number">1024000000000</span></span><br><span class="line">mds cache size = <span class="number">3000000</span></span><br><span class="line">mds bal fragment size max = <span class="number">10000</span></span><br><span class="line">mds session timeout = <span class="number">30</span></span><br><span class="line">mds session autoclose = <span class="number">30</span></span><br><span class="line">mds log max segments = <span class="number">100</span></span><br><span class="line">osd journal size = <span class="number">2048</span></span><br><span class="line">osd pool default size = <span class="number">3</span></span><br><span class="line">osd pool default min_size = <span class="number">1</span></span><br><span class="line">osd crush chooseleaf type = <span class="number">1</span></span><br><span class="line">osd recovery threads  = <span class="number">1</span></span><br><span class="line">osd mkfs_type = xfs</span><br><span class="line">mon osd full ratio = .<span class="number">90</span></span><br><span class="line">mon osd nearfull ratio = .<span class="number">85</span></span><br><span class="line">mon_pg_warn_max_per_osd = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line">[mon]</span><br><span class="line">mon clock drift allowed = .<span class="number">50</span></span><br><span class="line">mon osd down out interval = <span class="number">900</span></span><br><span class="line"></span><br><span class="line">[osd]</span><br><span class="line">tcp nodelay = false</span><br><span class="line">;osd filestore settings</span><br><span class="line">filestore xattr use omap = true</span><br><span class="line">filestore min sync interval = <span class="number">10</span></span><br><span class="line">filestore max sync interval = <span class="number">15</span></span><br><span class="line">filestore queue max ops = <span class="number">25000</span></span><br><span class="line">filestore queue max bytes = <span class="number">10485760</span></span><br><span class="line">filestore queue committing max ops = <span class="number">5000</span></span><br><span class="line">filestore queue committing max bytes = <span class="number">10485760000</span></span><br><span class="line">filestore_wbthrottle_xfs_bytes_start_flusher = <span class="number">500000000</span></span><br><span class="line">filestore_wbthrottle_xfs_indoes_start_flusher = <span class="number">500</span></span><br><span class="line">filestore_wbthrottle_xfs_indoes_hard_limit = <span class="number">500000</span></span><br><span class="line">filestore_wbthrottle_xfs_ios_start_flusher = <span class="number">50000</span></span><br><span class="line">filestore_wbthrottle_xfs_bytes_hard_limit = <span class="number">500000000</span></span><br><span class="line">filestore_wbthrottle_xfs_ios_hard_limit = <span class="number">500000</span></span><br><span class="line">filestore_fd_cache_random = true</span><br><span class="line">filestore op threads = <span class="number">4</span></span><br><span class="line">;osd journal settings</span><br><span class="line">journal max write bytes = <span class="number">1073714824</span></span><br><span class="line">journal max write entries = <span class="number">10000</span></span><br><span class="line">journal queue max ops = <span class="number">50000</span></span><br><span class="line">journal queue max bytes = <span class="number">10485760000</span></span><br><span class="line">;osd settings</span><br><span class="line">osd max object name len = <span class="number">256</span></span><br><span class="line">osd max object namespace len = <span class="number">64</span></span><br><span class="line">osd journal size = <span class="number">50000</span></span><br><span class="line">osd mkfs type = xfs</span><br><span class="line">osd mkfs options xfs = -f</span><br><span class="line">osd max write size = <span class="number">512</span></span><br><span class="line">osd client message size cap = <span class="number">2147483648</span></span><br><span class="line">osd deep scrub stride = <span class="number">131072</span></span><br><span class="line">osd op threads = <span class="number">8</span></span><br><span class="line">osd disk threads = <span class="number">4</span></span><br><span class="line">osd map cache size = <span class="number">1024</span></span><br><span class="line">osd map cache bl size = <span class="number">128</span></span><br><span class="line">osd mount options xfs = <span class="string">"rw,noexec,nodev,noatime,nodiratime,nobarrier"</span></span><br><span class="line">osd recovery op priority = <span class="number">4</span></span><br><span class="line">osd recovery max active = <span class="number">10</span></span><br><span class="line">osd max backfills = <span class="number">4</span></span><br><span class="line">osd pool default pg num = <span class="number">100</span></span><br><span class="line">osd pool default pgp num = <span class="number">100</span></span><br><span class="line"></span><br><span class="line">[client]</span><br><span class="line">rbd cache = true</span><br><span class="line">rbd cache size = <span class="number">268435456</span></span><br><span class="line">rbd cache max dirty = <span class="number">134217728</span></span><br><span class="line">rbd cache max dirty age = <span class="number">5</span></span><br><span class="line">rbd default features = <span class="number">1</span></span><br></pre></td></tr></table></figure>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/abitming.github.io/tags/Ceph，存储/" rel="tag"># Ceph，存储</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/abitming.github.io/2020/04/09/varnish那些事/" rel="next" title="Varnish缓存">
                <i class="fa fa-chevron-left"></i> Varnish缓存
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/abitming.github.io/2020/04/16/Prometheus/" rel="prev" title="基于Prometheus的监控平台">
                基于Prometheus的监控平台 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">小明</p>
              <p class="site-description motion-element" itemprop="description">IT技术类博客，主要是运维方向(Docker、DevOPS、Golang等)</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/abitming.github.io/archives/">
              
                  <span class="site-state-item-count">12</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">11</span>
                  <span class="site-state-item-name">tags</span>
                
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Ceph部署"><span class="nav-number">1.</span> <span class="nav-text">Ceph部署</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#一、环境准备-ceph-deploy"><span class="nav-number">1.0.1.</span> <span class="nav-text">一、环境准备(ceph-deploy)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#node-节点的YUM环境准备"><span class="nav-number">1.0.1.1.</span> <span class="nav-text">node 节点的YUM环境准备</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#二、安装部署"><span class="nav-number">1.0.2.</span> <span class="nav-text">二、安装部署</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1、创建集群"><span class="nav-number">1.0.2.1.</span> <span class="nav-text">1、创建集群</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2、修改副本"><span class="nav-number">1.0.2.2.</span> <span class="nav-text">2、修改副本</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3、网络设置"><span class="nav-number">1.0.2.3.</span> <span class="nav-text">3、网络设置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4、安装ceph"><span class="nav-number">1.0.2.4.</span> <span class="nav-text">4、安装ceph</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5、初始化MON"><span class="nav-number">1.0.2.5.</span> <span class="nav-text">5、初始化MON</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6、添加OSD"><span class="nav-number">1.0.2.6.</span> <span class="nav-text">6、添加OSD</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#6-1、在-OSD-节点上的准备工作"><span class="nav-number">1.0.2.6.1.</span> <span class="nav-text">6.1、在 OSD 节点上的准备工作</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#6-2、在管理节点准备-OSD"><span class="nav-number">1.0.2.6.2.</span> <span class="nav-text">6.2、在管理节点准备 OSD</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#6-3、在管理节点上激活-OSD"><span class="nav-number">1.0.2.6.3.</span> <span class="nav-text">6.3、在管理节点上激活 OSD</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7、密钥复制"><span class="nav-number">1.0.2.7.</span> <span class="nav-text">7、密钥复制</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8、检查集群状态"><span class="nav-number">1.0.2.8.</span> <span class="nav-text">8、检查集群状态</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#三、集群扩容"><span class="nav-number">1.0.3.</span> <span class="nav-text">三、集群扩容</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1、MON-新增"><span class="nav-number">1.0.3.1.</span> <span class="nav-text">1、MON 新增</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1-1-修改-ceph-conf-配置文件"><span class="nav-number">1.0.3.1.1.</span> <span class="nav-text">1.1 修改 ceph.conf 配置文件</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#1-2-新增-MON"><span class="nav-number">1.0.3.1.2.</span> <span class="nav-text">1.2 新增 MON</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2、OSD-新增"><span class="nav-number">1.0.3.2.</span> <span class="nav-text">2、OSD 新增</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#2-1-修改ceph-conf"><span class="nav-number">1.0.3.2.1.</span> <span class="nav-text">2.1 修改ceph.conf</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-2-目录授权"><span class="nav-number">1.0.3.2.2.</span> <span class="nav-text">2.2 目录授权</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-3-准备并激活"><span class="nav-number">1.0.3.2.3.</span> <span class="nav-text">2.3 准备并激活</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3、MDS-新增"><span class="nav-number">1.0.3.3.</span> <span class="nav-text">3、MDS 新增</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#四、集群管理"><span class="nav-number">1.1.</span> <span class="nav-text">四、集群管理</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1、创建Pool"><span class="nav-number">1.1.0.1.</span> <span class="nav-text">1、创建Pool</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2、创建-CephFS"><span class="nav-number">1.1.0.2.</span> <span class="nav-text">2、创建 CephFS</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3、CephFS用户授权"><span class="nav-number">1.1.0.3.</span> <span class="nav-text">3、CephFS用户授权</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4、创建RBD"><span class="nav-number">1.1.0.4.</span> <span class="nav-text">4、创建RBD</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5、数据控制"><span class="nav-number">1.1.0.5.</span> <span class="nav-text">5、数据控制</span></a></li></ol></li></ol><li class="nav-item nav-level-2"><a class="nav-link" href="#五、故障处理"><span class="nav-number">1.2.</span> <span class="nav-text">五、故障处理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#六、配置文件参考"><span class="nav-number">1.3.</span> <span class="nav-text">六、配置文件参考</span></a></li></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">小明</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/abitming.github.io/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/abitming.github.io/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/abitming.github.io/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/abitming.github.io/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/abitming.github.io/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/abitming.github.io/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/abitming.github.io/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/abitming.github.io/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/abitming.github.io/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/abitming.github.io/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/abitming.github.io/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
